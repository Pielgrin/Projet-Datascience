{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pierre - Pix2Pix with classes.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"xDrcpscuF5VY","colab_type":"code","outputId":"6d534312-5572-4f87-fa4d-34f85e05ec8a","executionInfo":{"status":"ok","timestamp":1579788360574,"user_tz":-60,"elapsed":26709,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DhStDSv1Ofax","colab_type":"code","outputId":"176800bd-eea3-4992-8a48-6bcda598ba46","executionInfo":{"status":"ok","timestamp":1579788369671,"user_tz":-60,"elapsed":4070,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}},"colab":{"base_uri":"https://localhost:8080/","height":80}},"source":["from __future__ import print_function, division\n","import numpy as np \n","import pandas as pd \n","import scipy\n","from glob import glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage import transform\n","\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","import datetime\n","import sys\n","import os\n","#from imageio import imread\n","import imageio\n","sys.path.append(\"/content/drive/My Drive/Projet DataScience\") #Path Kayou\n","from Pipeline.Degradation import UglyImage"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Un6wLQMdgRYv","colab_type":"code","colab":{}},"source":["class DataLoader():\n","  def __init__(self, img_res=(128,128)):\n","    self.img_res = img_res\n","    self.train_path_files = '/content/drive/My Drive/Projet DataScience/Data/Train/dataset_clean_degraded'\n","    self.val_path_files = '/content/drive/My Drive/Projet DataScience/Data/Val/'\n","\n","  def load_data(self, batch_size=1, is_val=True):\n","    \"\"\"\n","    Return couples of images to visualize progress of the networks after epochs\n","    \"\"\"\n","    \n","    path_files = self.train_path_files if not is_val else self.val_path_files\n","\n","    clean_images = []\n","    degraded_images = []\n","    \n","    files = os.listdir(path_files + '/clean/')\n","    batch_images = np.random.choice(files, size=batch_size)\n","\n","    for image in batch_images:\n","      clean = self.imread(path_files + '/clean/' + image)\n","      degraded = self.imread(path_files + '/degraded/' + image)\n","\n","      # Decrease resolution\n","      clean = transform.resize(clean, self.img_res)\n","      degraded = transform.resize(degraded, self.img_res)\n","\n","      # Data augmentation\n","      #if not is_val and np.random.random() < 0.5:\n","      #  clean_images = np.fliplr(clean_images)\n","      #  degraded_images = np.fliplr(degraded_images)\n","\n","      clean_images.append(clean)\n","      degraded_images.append(degraded)\n","\n","    #normalizing images\n","    clean_images = np.array(clean_images)/127.5 - 1.\n","    degraded_images = np.array(degraded_images)/127.5 -1.\n","\n","    return clean_images, degraded_images\n","\n","  def load_batch(self, batch_size=1, is_val=False):\n","    \"\"\"\n","    Same function as load_data except for the fact that is used during training to load image in batches\n","    \"\"\"\n","    \n","    path_files = self.train_path_files if not is_val else self.val_path_files\n","\n","    n_batches = batch_size\n","    files = os.listdir(path_files + '/clean/')\n","\n","    ugly = UglyImage(path=path_files + '/clean/', image_size=self.img_res)\n","\n","    for i in range(n_batches):\n","      batch = files[i*batch_size:(i+1)*batch_size]\n","      \n","      #gen_data = ugly.loadImg(batch)\n","      #degraded_images, clean_images = next(gen_data)\n","      clean_images = []\n","      degraded_images = []\n","\n","      for image in batch:\n","        clean_image_path = str(path_files + '/clean/' + image)\n","        degraded, clean = ugly.uglifyImage(clean_image_path)\n"," #       clean_image_path = str(path_files + '/clean/' + image)\n"," #       clean = self.imread(clean_image_path)\n"," #       degraded_image_path = str(path_files + '/degraded/' + image)\n"," #       degraded = self.imread(degraded_image_path)\n","\n","        # decrease resolution\n"," #       clean = transform.resize(clean, self.img_res)\n"," #       degraded = transform.resize(degraded, self.img_res)\n","\n","        # Data augmentation, trick to avoid overfitting\n","        #if not is_val and np.random.random() < 0.5:\n","        #  clean_images = np.fliplr(clean_images)\n","        #  degraded_images = np.fliplr(degraded_images)\n","        \n","        clean_images.append(clean)\n","        degraded_images.append(degraded)\n","\n","      #normalizing images\n","      clean_images = np.array(clean_images)/127.5 - 1.\n","      degraded_images = np.array(degraded_images)/127.5 -1.\n","\n","      yield clean_images, degraded_images\n","\n","  def imread(self, path):\n","    return imageio.imread(path).astype(np.float)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ht8RPXMkagaZ","colab_type":"code","colab":{}},"source":["class Pix2Pix():\n","  def __init__(self, img_rows=128, img_cols=128, channels=3):\n","    # Input shape\n","    self.img_rows = img_rows\n","    self.img_cols = img_cols\n","    self.channels = channels\n","\n","    self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","    # Configure DataLoader\n","    self.data_loader = DataLoader(img_res=(self.img_rows, self.img_cols))\n","\n","    # Calculate output shape of D (PatchGAN)\n","    patchrows = int(self.img_rows / 2**4)\n","    patchcols = int(self.img_cols / 2**4)\n","    self.disc_patch = (patchrows, patchcols, 1)\n","\n","    # Number of filters in the first layer of G and D\n","    self.gf = 64\n","    self.df = 64\n","\n","    optimizer = Adam(0.0002, 0.5)\n","\n","    self.generator_weights_filepath = 'weights_generator.hdf5'\n","    self.discriminator_weights_filepath = 'weights_discriminator.hdf5'\n","\n","\n","    # Build and compile the discriminator\n","    self.discriminator = self.build_discriminator()\n","    self.discriminator.compile(loss='mse',\n","                optimizer=optimizer,\n","                metrics=['accuracy'])\n","\n","    # Build the generator\n","    self.generator = self.build_generator()\n","\n","    # Input images and their conditioning images\n","    clean_image = Input(shape=self.img_shape)\n","    degraded_image = Input(shape=self.img_shape)\n","\n","    # By conditioning on degraded_image generate a fake version of clean_image\n","    fake_clean_image = self.generator(degraded_image)\n","\n","    # For the combined model we will only train the generator\n","    self.discriminator.trainable = False\n","\n","    # Discriminators determines validity of translated images / condition pairs\n","    valid = self.discriminator([fake_clean_image, degraded_image])\n","\n","    self.combined = Model(inputs=[clean_image, degraded_image], outputs=[valid, fake_clean_image])\n","    self.combined.compile(loss=['mse', 'mae'],\n","                                  loss_weights=[1, 100],\n","                                  optimizer=optimizer)\n","    \n","  \n","  def build_generator(self):\n","    \"\"\"\n","    U-Net Generator (to generate image)\n","    \"\"\"\n","\n","    def conv2d(input_layer, filters, f_size=4, bn=True):\n","      \"\"\"\n","      Layers used during downsampling\n","      \"\"\"\n","      d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(input_layer)\n","      d = LeakyReLU(alpha=0.2)(d)\n","      \n","      if bn:\n","        d = BatchNormalization(momentum=0.8)(d)\n","      \n","      return d\n","\n","    def deconv2d(input_layer, skip_input, filters, f_size=4, dropout_rate=0):\n","      \"\"\"\n","      Layers used during downsampling\n","      \"\"\"\n","      u = UpSampling2D(size=2)(input_layer)\n","      u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n","\n","      if dropout_rate:\n","        u = Dropout(dropout_rate)(u)\n","      \n","      u = BatchNormalization(momentum=0.8)(u)\n","      u = Concatenate()([u, skip_input])\n","\n","      return u\n","\n","    #Image Input\n","    d0 = Input(shape=self.img_shape)\n","\n","    #Downsampling\n","    d1 = conv2d(d0, self.gf, bn=False)\n","    d2 = conv2d(d1, self.gf*2)\n","    d3 = conv2d(d2, self.gf*4)\n","    d4 = conv2d(d3, self.gf*8)\n","    d5 = conv2d(d4, self.gf*8)\n","    d6 = conv2d(d5, self.gf*8)\n","    d7 = conv2d(d6, self.gf*8)\n","\n","    # Upsampling\n","    u1 = deconv2d(d7, d6, self.gf*8)\n","    u2 = deconv2d(u1, d5, self.gf*8)\n","    u3 = deconv2d(u2, d4, self.gf*8)\n","    u4 = deconv2d(u3, d3, self.gf*4)\n","    u5 = deconv2d(u4, d2, self.gf*2)\n","    u6 = deconv2d(u5, d1, self.gf)\n","\n","    u7 = UpSampling2D(size=2)(u6)\n","    output_img = Conv2D(self.channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n","\n","    return Model(d0, output_img)\n","\n","  \n","  def build_discriminator(self):\n","  \n","    def d_layer(input_layer, filters, f_size=4, bn=True):\n","      \"\"\"\n","      Discriminator layer\n","      \"\"\"\n","      d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(input_layer)\n","      d = LeakyReLU(alpha=0.2)(d)\n","\n","      if bn:\n","        d = BatchNormalization(momentum=0.8)(d)\n","      return d\n","\n","    clean_image = Input(shape=self.img_shape)\n","    degraded_image = Input(shape=self.img_shape)\n","\n","    # Concatenate image and conditioning image by chanels to produce input\n","    combined_imgs = Concatenate(axis=-1)([clean_image, degraded_image])\n","\n","    d1 = d_layer(combined_imgs, self.df, bn=False)\n","    d2 = d_layer(d1, self.df*2)\n","    d3 = d_layer(d2, self.df*4)\n","    d4 = d_layer(d3, self.df*8)\n","\n","    validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","    return Model([clean_image, degraded_image], validity)\n","\n","  \n","  def train(self, epochs, batch_size=1, show_interval=10):\n","    start_time = datetime.datetime.now()\n","\n","    generator_best_loss = None\n","    discriminator_best_loss = None\n","\n","    # Adversarial loss ground truths\n","    valid = np.ones((batch_size,) + self.disc_patch)\n","    fake = np.zeros((batch_size,) + self.disc_patch)\n","\n","    for epoch in range(epochs):\n","        #print(\"start epoch : \" + str(epoch))\n","        for batch_i, (clean_images, degraded_images) in enumerate(self.data_loader.load_batch(batch_size)):\n","            #print(\"start step : \" + str(batch_i))\n","\n","            # Train disciminator\n","\n","            # Condition on degraded_images and translated version\n","            fake_clean_images = self.generator.predict(degraded_images)\n","\n","            # Train the disciminators (orginal images = real / generated = Fake)\n","            d_loss_real = self.discriminator.train_on_batch([clean_images, degraded_images], valid)\n","            d_loss_fake = self.discriminator.train_on_batch([fake_clean_images, degraded_images], fake)\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","\n","            # Train generator\n","            g_loss = self.combined.train_on_batch([clean_images, degraded_images], [valid, clean_images])\n","            elapsed_time = datetime.datetime.now() - start_time\n","        \n","        \n","        if epoch % show_interval == 0:\n","          # Plot the progress\n","          print(\"[Epoch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, epochs, d_loss[0], 100*d_loss[1], g_loss[0], elapsed_time))\n","\n","          # If at show interval => show generated image samples\n","          self.show_images(epoch, batch_i)\n","\n","        # Save models\n","        for model, best_loss, loss, model_weights_filepath in [[self.generator, generator_best_loss, g_loss[0], self.generator_weights_filepath], [self.discriminator, discriminator_best_loss, d_loss[0], self.discriminator_weights_filepath]]:\n","          if best_loss == None or best_loss > loss:\n","            best_loss = loss\n","            #model.save_weights(model_weights_filepath, True)\n","            model.save('model_saved_filepath.h5')\n","          else:\n","            pass\n","\n","  def test(self, degraded_images, filepath_generator_weights):\n","    if os.path.isfile(filepath_generator_weights):\n","      self.generator.load_weights(filepath_generator_weights, True)\n","      print('generator weights loaded')\n","    else:\n","      print('ERROR : Generator weights not loaded')\n","    \n","    clean_images = self.generator.predict(degraded_images)\n","    return clean_images\n","\n","  def show_images(self, epoch, batch_i):\n","        \n","    r, c = 3, 3\n","\n","    clean_images, degraded_images = self.data_loader.load_data(batch_size=3, is_val=True)\n","    fake_clean_images = self.generator.predict(degraded_images)\n","\n","    gen_imgs = np.concatenate([degraded_images, fake_clean_images, clean_images])\n","\n","    # Rescale images 0 - 1\n","    gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","    titles = ['Input', 'Output', 'Ground Truth']\n","    fig, axs = plt.subplots(r, c)\n","    fig.set_size_inches(12, 12)\n","    cnt = 0\n","    for i in range(r):\n","      for j in range(c):\n","        axs[i,j].imshow(gen_imgs[cnt])\n","        axs[i, j].set_title(titles[i])\n","        axs[i,j].axis('off')\n","        cnt += 1\n","    plt.show()\n","    plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RG_dTZ2q72ts","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":395},"outputId":"808556bd-f986-4a02-ae25-195841290b73","executionInfo":{"status":"error","timestamp":1579790463298,"user_tz":-60,"elapsed":76842,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}}},"source":["gan = Pix2Pix()\n","gan.train(epochs=15, batch_size=16, show_interval=1)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["(128, 128)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-d1933892d59e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPix2Pix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-4654f330302f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, batch_size, show_interval)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m#print(\"start epoch : \" + str(epoch))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mclean_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegraded_images\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;31m#print(\"start step : \" + str(batch_i))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-07e2aa42680e>\u001b[0m in \u001b[0;36mload_batch\u001b[0;34m(self, batch_size, is_val)\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mclean_image_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_files\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/clean/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mdegraded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mugly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muglifyImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_image_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m  \u001b[0;31m#       clean_image_path = str(path_files + '/clean/' + image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m  \u001b[0;31m#       clean = self.imread(clean_image_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/Projet DataScience/Pipeline/Degradation.py\u001b[0m in \u001b[0;36muglifyImage\u001b[0;34m(self, pathImg, blackWhiteImg)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print(self.path + filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m#print(self.image_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathImg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m#imgs_clean.append(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"EtBKPZ3tA6h3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"outputId":"748281b2-eea2-436e-f105-53f155a0f593","executionInfo":{"status":"error","timestamp":1579790953876,"user_tz":-60,"elapsed":2833,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}}},"source":["gan2 = Pix2Pix()\n","gan2.load_weights('/content/drive/My Drive/Projet DataScience/Weights/weights_generator_loss_4.837722.hdf5')\n","one_image = imageio.imread('/content/drive/My Drive/Projet DataScience/Data/Test/Photo/Dataset/0003.jpg').astype(np.float)\n","one_image = transform.resize(one_image, (128,128))\n","\n","degraded_images = [one_image]\n","\n","degraded_images = np.array(degraded_images)/127.5 - 1.\n","\n","new_images = gan2.test(degraded_images, '/content/drive/My Drive/Projet DataScience/Weights/weights_generator_loss_4.837722.hdf5')\n"],"execution_count":53,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-0fc6daeb0c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgan2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPix2Pix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgan2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Projet DataScience/Weights/weights_generator_loss_4.837722.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mone_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Projet DataScience/Data/Test/Photo/Dataset/0003.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mone_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Pix2Pix' object has no attribute 'load_weights'"]}]},{"cell_type":"code","metadata":{"id":"_tWE8L9TxiNH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":265},"outputId":"6fd65a1c-7c26-4a41-bb73-cd9bbf80a0ac","executionInfo":{"status":"ok","timestamp":1579790726460,"user_tz":-60,"elapsed":7363,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}}},"source":["from matplotlib import pyplot as plt\n","new_image = new_images[0]\n","new_image = np.asarray(new_image) * 127.5 + 1.\n","plt.imshow(new_image)\n","plt.axis('off')\n","plt.show()"],"execution_count":52,"outputs":[{"output_type":"stream","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"],"name":"stderr"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAD5UlEQVR4nO3dbVLTYABG0bwO23I77smFuAL3ZfxB\nLVAKJEHgNjnHYWCUL2e8fd5+SMc8zxPQ8+2rvwHgOnFClDghSpwQJU6Iunvjz92UCx9vXPtNywlR\n4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQ\nJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJ\nUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqc\nECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LE\nCVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFK\nnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROi\nxAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDgh\nSpwQJU6IEidEiROixAlR4vwk4/QCS4kTou6WvNOYpmkaSy73f9y/mn++8QlXbsg8b/u4d5nPr05v\nTd9Pr3+v/Ezj0fd9fuv0d5qfvztM02Q5IWvM88uX3WMMF+xbrFn6ebaeXP2HYjkhatF1TlZac914\njPPF5munGI7HcoaMMZ7ceMSxiROiHGuDvmw9L47VDtlfy3JClOXkwcViv2e/3bj1fuLkQ7x2NBfu\nMo61EGU52Wie1h58f/2xmGtYToiynDyz/DqhJfxI4uTMDTUtjrUQJU6IEidEiROixAlR4oQod6Uc\nnLtPuiwnRFnOA7KWt8FyQpTl3DELedssJ0SJE6Ica3nR6p8C6Kkl/ivLCVGWk2c2/9S9R08t8Ro3\nVC1jOSFKnHw6zwmzjGPtjv0LYO0x8vzeG46fl9Fd/dq6XMRyQpTlPICtC7rFoq/h9qBFLCdEiROi\nxAlR4oQocUKUOCFKnBAlTogSJ0R5hNCBPHnc6+mRPB6s02U5IUqcRzXG/QtZ4oQocR6c//jc5Qah\ng/PzfLosJ0RZzoOymH2WE6LECVGOtTtzfkIEp9abZzkhSpw7M06/uH3ihCjXOXfGXST7Ic4dEOQ+\nOdZClOW8YfZy3ywnRFnOW+a65q5ZTogSJ0SJE6LECVHDHdjQZDkhSpwQJU6IEidEiROixAlRfwEw\nuWedXO1+XAAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"6kIy_B16xk2a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":283},"outputId":"90c26333-0771-42a6-9de9-828b32bbf93c","executionInfo":{"status":"error","timestamp":1579790226079,"user_tz":-60,"elapsed":502,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}}},"source":["type(np.asarray(new_image, dtype=float))"],"execution_count":33,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-402fcb430804>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."]}]},{"cell_type":"code","metadata":{"id":"6YfrVezryaqC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}