{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pierre - Pix2Pix.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bdg_1SR6ksvW","colab_type":"code","outputId":"1760e0b5-246a-47fd-ea89-2895d317c643","executionInfo":{"status":"ok","timestamp":1579684262325,"user_tz":-60,"elapsed":5440,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["!pip install imageio"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (2.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from imageio) (1.17.5)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio) (6.2.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xDrcpscuF5VY","colab_type":"code","outputId":"3a9a1c95-becf-47dc-ff1f-296682d4f493","executionInfo":{"status":"ok","timestamp":1579684262329,"user_tz":-60,"elapsed":5432,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A-u2ju6jFvhi","colab_type":"code","outputId":"714d346e-ca7f-4079-b7aa-b123e7216945","executionInfo":{"status":"ok","timestamp":1579684265687,"user_tz":-60,"elapsed":8783,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["!cd 'drive/My Drive/Projet DataSience/dataset_clean_degraded' && ls"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/bin/bash: line 0: cd: drive/My Drive/Projet DataSience/dataset_clean_degraded: No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DhStDSv1Ofax","colab_type":"code","outputId":"39ea7b7a-3e9c-45b9-dc7b-9a4483495121","executionInfo":{"status":"ok","timestamp":1579684267567,"user_tz":-60,"elapsed":10655,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}},"colab":{"base_uri":"https://localhost:8080/","height":97}},"source":["import numpy as np \n","import pandas as pd \n","import scipy\n","from glob import glob\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from skimage import transform\n","from __future__ import print_function, division\n","\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","import datetime\n","import sys\n","import os\n","#from imageio import imread\n","import imageio"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"F0dl3_5tmrDE","colab_type":"code","colab":{}},"source":["def load_data(batch_size=1, is_val=True):\n","  \"\"\"\n","   Return 3 couples of images to visualize progress of the networks after epochs\n","  \"\"\"\n","\n","  path_files = 'drive/My Drive/Projet DataScience/Data/Train/dataset_clean_degraded' if not is_val else 'drive/My Drive/Projet DataScience/Data/Val'\n","  img_res=(128,128)\n","\n","  clean_images = []\n","  degraded_images = []\n","\n","  files = os.listdir(path_files + '/clean/')\n","  batch_images = np.random.choice(files, size=batch_size)\n","    \n","  for image in batch_images:\n","    clean = imread(path_files + '/clean/' + image)\n","    degraded = imread(path_files + '/degraded/' + image)\n","\n","    # decrease resolution\n","    clean = transform.resize(clean, img_res)\n","    degraded = transform.resize(degraded, img_res)\n","\n","    # Data augmentation, trick to avoid overfitting\n","    #if not is_val and np.random.random() < 0.5:\n","    #  clean_images = np.fliplr(clean_images)\n","    #  degraded_images = np.fliplr(degraded_images)\n","\n","    clean_images.append(clean)\n","    degraded_images.append(degraded)\n","\n","  #normalizing images\n","  clean_images = np.array(clean_images)/127.5 - 1.\n","  degraded_images = np.array(degraded_images)/127.5 -1.\n","\n","  return clean_images, degraded_images"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWxBLmI9WY-a","colab_type":"code","colab":{}},"source":["def load_batch(batch_size=1, is_val=False):\n","  \"\"\"\n","  Same function as load_data except for the fact that is used during training to load image in batches\n","  \"\"\"\n","  \n","  path_files = 'drive/My Drive/Projet DataScience/Data/Train/dataset_clean_degraded' if not is_val else 'drive/My Drive/Projet DataScience/Data/Val'\n","  img_res=(128,128)\n","\n","  n_batches = batch_size\n","  files = os.listdir(path_files + '/clean/')\n","\n","  for i in range(n_batches):\n","     batch = files[i*batch_size:(i+1)*batch_size]\n","     \n","     clean_images = []\n","     degraded_images = []\n","     ugly = UglyImage(img_size=(128,128))\n","     clean_images, degraded_images = ugly.loadimg(32)\n","     #clean_image[0,,,:]/255\n","\n","     for image in batch:\n","       clean = imread(path_files + '/clean/' + image)\n","       degraded = imread(path_files + '/degraded/' + image)\n","\n","       # decrease resolution\n","       clean = transform.resize(clean, img_res)\n","       degraded = transform.resize(degraded, img_res)\n","\n","       # Data augmentation, trick to avoid overfitting\n","       #if not is_val and np.random.random() < 0.5:\n","       #  clean_images = np.fliplr(clean_images)\n","       #  degraded_images = np.fliplr(degraded_images)\n","       \n","       clean_images.append(clean)\n","       degraded_images.append(degraded)\n","\n","     #normalizing images\n","     clean_images = np.array(clean_images)/127.5 - 1.\n","     degraded_images = np.array(degraded_images)/127.5 -1.\n","\n","     yield clean_images, degraded_images"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4vpK-HnNZgPY","colab_type":"code","colab":{}},"source":["def imread(path):\n","  #return scipy.misc.imread(path, mode='RGB').astype(np.float)\n","  return imageio.imread(path).astype(np.float)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tYfKf567iSHz","colab_type":"code","colab":{}},"source":["def build_generator():\n","  \"\"\"\n","  U-Net Generator (to generate image)\n","  \"\"\"\n","\n","  def conv2d(input_layer, filters, f_size=4, bn=True):\n","    \"\"\"\n","    Layers used during downsampling\n","    \"\"\"\n","    d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(input_layer)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    \n","    if bn:\n","      d = BatchNormalization(momentum=0.8)(d)\n","    \n","    return d\n","\n","  def deconv2d(input_layer, skip_input, filters, f_size=4, dropout_rate=0):\n","    \"\"\"\n","    Layers used during downsampling\n","    \"\"\"\n","    u = UpSampling2D(size=2)(input_layer)\n","    u = Conv2D(filters, kernel_size=f_size, strides=1, padding='same', activation='relu')(u)\n","\n","    if dropout_rate:\n","      u = Dropout(dropout_rate)(u)\n","    \n","    u = BatchNormalization(momentum=0.8)(u)\n","    u = Concatenate()([u, skip_input])\n","\n","    return u\n","\n","  #Image Input\n","  d0 = Input(shape=img_shape)\n","\n","  #Downsampling\n","  d1 = conv2d(d0, gf, bn=False)\n","  d2 = conv2d(d1, gf*2)\n","  d3 = conv2d(d2, gf*4)\n","  d4 = conv2d(d3, gf*8)\n","  d5 = conv2d(d4, gf*8)\n","  d6 = conv2d(d5, gf*8)\n","  d7 = conv2d(d6, gf*8)\n","\n","  # Upsampling\n","  u1 = deconv2d(d7, d6, gf*8)\n","  u2 = deconv2d(u1, d5, gf*8)\n","  u3 = deconv2d(u2, d4, gf*8)\n","  u4 = deconv2d(u3, d3, gf*4)\n","  u5 = deconv2d(u4, d2, gf*2)\n","  u6 = deconv2d(u5, d1, gf)\n","\n","  u7 = UpSampling2D(size=2)(u6)\n","  output_img = Conv2D(channels, kernel_size=4, strides=1, padding='same', activation='tanh')(u7)\n","\n","  return Model(d0, output_img)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"81htnOjKiToW","colab_type":"code","colab":{}},"source":["def build_discriminator():\n","  \n","  def d_layer(input_layer, filters, f_size=4, bn=True):\n","    \"\"\"\n","    Discriminator layer\n","    \"\"\"\n","    d = Conv2D(filters, kernel_size=f_size, strides=2, padding='same')(input_layer)\n","    d = LeakyReLU(alpha=0.2)(d)\n","\n","    if bn:\n","      d = BatchNormalization(momentum=0.8)(d)\n","    return d\n","\n","  clean_image = Input(shape=img_shape)\n","  degraded_image = Input(shape=img_shape)\n","\n","  # Concatenate image and conditioning image by chanels to produce input\n","  combined_imgs = Concatenate(axis=-1)([clean_image, degraded_image])\n","\n","  d1 = d_layer(combined_imgs, df, bn=False)\n","  d2 = d_layer(d1, df*2)\n","  d3 = d_layer(d2, df*4)\n","  d4 = d_layer(d3, df*8)\n","\n","  validity = Conv2D(1, kernel_size=4, strides=1, padding='same')(d4)\n","\n","  return Model([clean_image, degraded_image], validity)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e84j5RyXL3sT","colab_type":"code","outputId":"1952a70e-939f-4900-ec71-38a5649417a2","executionInfo":{"status":"ok","timestamp":1579689121554,"user_tz":-60,"elapsed":2910,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Input shape\n","img_rows = 128\n","img_cols = 128\n","channels = 3\n","\n","img_shape = (img_rows, img_cols, channels)\n","\n","# Calculate output shape of D (PatchGAN)\n","patchrows = int(img_rows / 2**4)\n","patchcols = int(img_cols / 2**4)\n","disc_patch = (patchrows, patchcols, 1)\n","\n","# Number of filters in the first layer of G and D\n","gf = 64\n","df = 64\n","\n","optimizer = Adam(0.002, 0.5)\n","\n","# Build and compile the discriminator\n","discriminator = build_discriminator()\n","discriminator.compile(loss='mse',\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","# Load discriminator weights\n","filepath_discriminator_weights = 'weights_discriminator_loss_0.102622256.hdf5'\n","if os.path.isfile(filepath_discriminator_weights):\n","  discriminator.load_weights(filepath_discriminator_weights, True)\n","  print('discriminator weights loaded')\n","\n","# Build the generator\n","generator = build_generator()\n","\n","# Load generator weights\n","filepath_generator_weights = 'weights_generator_loss_5.8947883.hdf5'\n","if os.path.isfile(filepath_generator_weights):\n","  generator.load_weights(filepath_generator_weights, True)\n","  print('generator weights loaded')\n","\n","# Input images and their conditioning images\n","clean_image = Input(shape=img_shape)\n","degraded_image = Input(shape=img_shape)\n","\n","# By conditioning on degraded_image generate a fake version of clean_image\n","fake_clean_image = generator(degraded_image)\n","\n","# For the combined model we will only train the generator\n","discriminator.trainable = False\n","\n","# Discriminators determines validity of translated images / condition pairs\n","valid = discriminator([fake_clean_image, degraded_image])\n","\n","combined = Model(inputs=[clean_image, degraded_image], outputs=[valid, fake_clean_image])\n","combined.compile(loss=['mse', 'mae'],\n","                              loss_weights=[1, 100],\n","                              optimizer=optimizer)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["discriminator weights loaded\n","generator weights loaded\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VJNXaWYhQjr8","colab_type":"code","colab":{}},"source":["def show_images(epoch, batch_i):\n","        \n","  r, c = 3, 3\n","\n","  clean_images, degraded_images = load_data(batch_size=3, is_val=True)\n","  fake_clean_images = generator.predict(degraded_images)\n","\n","  gen_imgs = np.concatenate([degraded_images, fake_clean_images, clean_images])\n","\n","  # Rescale images 0 - 1\n","  gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","  titles = ['Input', 'Output', 'Ground Truth']\n","  fig, axs = plt.subplots(r, c)\n","  fig.set_size_inches(12, 12)\n","  cnt = 0\n","  for i in range(r):\n","    for j in range(c):\n","      axs[i,j].imshow(gen_imgs[cnt])\n","      axs[i, j].set_title(titles[i])\n","      axs[i,j].axis('off')\n","      cnt += 1\n","  plt.show()\n","  plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H2CkwxWMRiJl","colab_type":"code","colab":{}},"source":["def train(epochs, batch_size=1, show_interval=10):\n","    start_time = datetime.datetime.now()\n","\n","    # Adversarial loss ground truths\n","    valid = np.ones((batch_size,) + disc_patch)\n","    fake = np.zeros((batch_size,) + disc_patch)\n","\n","    for epoch in range(epochs):\n","        #print(\"start epoch : \" + str(epoch))\n","        for batch_i, (clean_images, degraded_images) in enumerate(load_batch(batch_size)):\n","            #print(\"start step : \" + str(batch_i))\n","\n","            # Train disciminator\n","\n","            # Condition on degraded_images and translated version\n","            fake_clean_images = generator.predict(degraded_images)\n","\n","            # Train the disciminators (orginal images = real / generated = Fake)\n","            d_loss_real = discriminator.train_on_batch([clean_images, degraded_images], valid)\n","            d_loss_fake = discriminator.train_on_batch([fake_clean_images, degraded_images], fake)\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","\n","\n","            # Train generator\n","            g_loss = combined.train_on_batch([clean_images, degraded_images], [valid, clean_images])\n","            elapsed_time = datetime.datetime.now() - start_time\n","        \n","        \n","        if epoch % show_interval == 0:\n","          # Plot the progress\n","          print(\"[Epoch %d/%d] [D loss: %f, acc: %3d%%] [G loss: %f] time: %s\" % (epoch, epochs, d_loss[0], 100*d_loss[1], g_loss[0], elapsed_time))\n","\n","          # If at show interval => show generated image samples\n","          show_images(epoch, batch_i)\n","\n","    # Save models\n","    generator_weights_filepath = 'weights_generator_loss_' + str(g_loss[0]) + '.hdf5'\n","    discriminator_weights_filepath = 'weights_discriminator_loss_' + str(d_loss[0]) + '.hdf5'\n","    \n","    generator.save_weights(generator_weights_filepath, True)\n","    discriminator.save_weights(discriminator_weights_filepath, True)      "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-zLNkuKWdjw","colab_type":"code","outputId":"dc64bb78-f244-4720-9e9a-a432e257db0d","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1PcK1DjwR7LuT88JUAmeqO2XXWKSGnF5I"},"executionInfo":{"status":"ok","timestamp":1579707939588,"user_tz":-60,"elapsed":9579424,"user":{"displayName":"Pierre P","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCQnoIia9fbr43e9wx5JU81B6ibo7x3zUqjJDyAMw=s64","userId":"03988573648607851298"}}},"source":["train(epochs=120, batch_size=32, show_interval=3)"],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"Un6wLQMdgRYv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ht8RPXMkagaZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}